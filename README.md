# Weather-ETL-Pipeline🌦️
An ETL pipeline built with Airflow to extract, transform, and load weather data into a PostgreSQL database. This project demonstrates ETL processes with Dockerized services and real-world weather datasets

# 🚀 Features
- Extract: Weather data from external APIs or CSV files.
- Transform: Clean and prepare data (e.g., handle missing values, format dates).
- Load: Store the transformed data in a PostgreSQL database.
- Scheduling: Automate tasks using Airflow DAGs.

# 🛠️ Technologies Used
- Airflow: Workflow orchestration
- PostgreSQL: Database for storing processed data
- Docker: Containerization
- Python: Data transformation scripts
- Pandas: Data wrangling

# ⚙️ Setup Instructions
1. Prerequisites
  - Docker installed on your system
  - Pyhton installed on your system
  - Git for cloning the repository
2. Clone the Repository
3. Install Dependencies
4. Run with Docker Compose
5. Access Airflow Web UI
  - Open your browser and navigate to http://localhost:8080.
6. Test the ETL Pipeline
